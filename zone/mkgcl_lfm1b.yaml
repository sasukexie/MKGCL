# dataset config
field_separator: "\t"
seq_separator: " "
data_path: 'dataset/'
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
RATING_FIELD: rating
HEAD_ENTITY_ID_FIELD: head_id
TAIL_ENTITY_ID_FIELD: tail_id
RELATION_ID_FIELD: relation_id
ENTITY_ID_FIELD: entity_id
NEG_PREFIX: neg_
LABEL_FIELD: label
load_col:
    inter: [user_id, item_id, rating]
    kg: [head_id, relation_id, tail_id]
    link: [item_id, entity_id]

# data filtering for interactions
val_interval:
    rating: "[3,inf)"
unused_col:
    inter: [rating]

user_inter_num_interval: "[10,inf)"
item_inter_num_interval: "[10,inf)"

# data preprocessing for knowledge graph triples
kg_reverse_r: True
entity_kg_num_interval: "[5,inf)"
relation_kg_num_interval: "[5,inf)"

# training and evaluation
epochs: 500
train_batch_size: 4096
eval_batch_size: 409600 #40960000
valid_metric: NDCG@10
train_neg_sample_args:
    distribution: uniform
#    sample_num: 1
#    dynamic: False
save_dataloaders: True
#eval_args:
#  split: {'RS':[0.8,0.1,0.1]}

# model
embedding_size: 64
#learning_rate: 0.001 #0.001
kg_embedding_size: 64
layers: [64]
mess_dropout: 0.1
reg_weight: 1e-05
aggregator_type: 'bi' #['gcn', 'graphsage', 'bi']
# mkgcl
temperature1: 1.0 #1.0;0.007,1.0,0.5,0.1,2
temperature2: 1.0 #1.0;0.007,1.0,0.5,0.1,2
mini_batch_size_mul: 32 #32
#m: 0.0 #1-m
n_layers_q: 1 # 2
n_layers_k: 1 # 2
noise_base_a: 10 #10
noise_base_m: 1e-3 #1e-2
u_noise_base: 1e-3 #0.01
e_noise_base: 1e-3 #0.01
r_noise_base: 1e-3 #0.01
r_s_len: 1e-2 #0.01
migcl_data_aug: 'sen_a' #ed;gen_a:ed,gen_m:ed,gen_agen_m;sen_a,sen_m
mulcl_data_aug: 'sen_a' #sen_a,sen_m
r_data_aug: 'sen_a' #sen_a,sen_m,r_s(Relation Substitute)
open_migcl: True #True,False
open_mulcl: True #True,False
open_r: True #True,False
open_ali_uni: False,
open_represent: True,
align_w: 1,  # Alignment loss weight
unif_w: 1,  # Uniformity loss weight
align_alpha: 2,  # alpha in alignment loss
unif_t: 2,  # t in uniformity loss
log_interval: 10,  # Number of iterations between logs